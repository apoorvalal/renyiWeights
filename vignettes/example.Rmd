---
title: Renyi Weights for Causal Inference
author: Apoorva Lal
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    self_contained: true
    theme: flatly
    highlight: tango
    code_folding: hide
    toc: true
    toc_float: false
    toc_depth: 3
    fig_width:  10
    fig_height: 8
---


<!--- For HTML renders - selection from math_shortcuts.tex --->
`r if (!knitr:::is_latex_output()) '
$\\DeclareMathOperator*{\\argmin}{argmin}$
$\\newcommand{\\var}{\\mathrm{Var}}$
$\\newcommand{\\epsi}{\\varepsilon}$
$\\newcommand{\\phii}{\\varphi}$
$\\newcommand{\\tra}{^{\\top}}$
$\\newcommand{\\sumin}{\\sum_{i=1}^n}$
$\\newcommand{\\sumiN}{\\sum_{i=1}^n}$
$\\newcommand{\\norm}[1]{\\left\\Vert{#1} \\right\\Vert}$
$\\newcommand\\Bigpar[1]{\\left( #1 \\right )}$
$\\newcommand\\Bigbr[1]{\\left[ #1 \\right ]}$
$\\newcommand\\Bigcr[1]{\\left\\{ #1 \\right \\}}$
$\\newcommand\\SetB[1]{\\left\\{ #1 \\right\\}}$
$\\newcommand\\Sett[1]{\\mathcal{#1}}$
$\\newcommand{\\Data}{\\mathcal{D}}$
$\\newcommand{\\Ubr}[2]{\\underbrace{#1}_{\\text{#2}}}$
$\\newcommand{\\Obr}[2]{ \\overbrace{#1}^{\\text{#2}}}$
$\\newcommand{\\sumiN}{\\sum_{i=1}^N}$
$\\newcommand{\\dydx}[2]{\\frac{\\partial #1}{\\partial #2}}$
$\\newcommand\\Indic[1]{\\mathds{1}_{#1}}$
$\\newcommand{\\Realm}[1]{\\mathbb{R}^{#1}}$
$\\newcommand{\\Exp}[1]{\\mathbb{E}\\left[#1\\right]}$
$\\newcommand{\\Expt}[2]{\\mathbb{E}_{#1}\\left[#2\\right]}$
$\\newcommand{\\Var}[1]{\\mathbb{V}\\left[#1\\right]}$
$\\newcommand{\\Covar}[1]{\\text{Cov}\\left[#1\\right]}$
$\\newcommand{\\Prob}[1]{\\mathbf{Pr}\\left(#1\\right)}$
$\\newcommand{\\Supp}[1]{\\text{Supp}\\left[#1\\right]}$
$\\newcommand{\\doyx}{\\Prob{Y \\, |\\,\\mathsf{do} (X = x)}}$
$\\newcommand{\\doo}[1]{\\Prob{Y |\\,\\mathsf{do} (#1) }}$
$\\newcommand{\\R}{\\mathbb{R}}$
$\\newcommand{\\Z}{\\mathbb{Z}}$
$\\newcommand{\\wh}[1]{\\widehat{#1}}$
$\\newcommand{\\wt}[1]{\\widetilde{#1}}$
$\\newcommand{\\wb}[1]{\\overline{#1}}$
$\\newcommand\\Ol[1]{\\overline{#1}}$
$\\newcommand\\Ul[1]{\\underline{#1}}$
$\\newcommand\\Str[1]{#1^{*}}$
$\\newcommand{\\F}{\\mathsf{F}}$
$\\newcommand{\\ff}{\\mathsf{f}}$
$\\newcommand{\\Cdf}[1]{\\mathbb{F}\\left(#1\\right)}$
$\\newcommand{\\Cdff}[2]{\\mathbb{F}_{#1}\\left(#2\\right)}$
$\\newcommand{\\Pdf}[1]{\\mathsf{f}\\left(#1\\right)}$
$\\newcommand{\\Pdff}[2]{\\mathsf{f}_{#1}\\left(#2\\right)}$
$\\newcommand{\\dd}{\\mathsf{d}}$
$\\newcommand\\Normal[1]{\\mathcal{N} \\left( #1 \\right )}$
$\\newcommand\\Unif[1]{\\mathsf{U} \\left[ #1 \\right ]}$
$\\newcommand\\Bern[1]{\\mathsf{Bernoulli} \\left( #1 \\right )}$
$\\newcommand\\Binom[1]{\\mathsf{Bin} \\left( #1 \\right )}$
$\\newcommand\\Pois[1]{\\mathsf{Poi} \\left( #1 \\right )}$
$\\newcommand\\BetaD[1]{\\mathsf{Beta} \\left( #1 \\right )}$
$\\newcommand\\Diri[1]{\\mathsf{Dir} \\left( #1 \\right )}$
$\\newcommand\\Gdist[1]{\\mathsf{Gamma} \\left( #1 \\right )}$
$\\def\\mbf#1{\\mathbf{#1}}$
$\\def\\mrm#1{\\mathrm{#1}}$
$\\def\\mbi#1{\\boldsymbol{#1}}$
$\\def\\ve#1{\\mbi{#1}}$
$\\def\\vee#1{\\mathbf{#1}}$
$\\newcommand{\\Mat}[1]{\\mathbf{#1}}$
$\\newcommand{\\eucN}[1]{\\norm{#1}}$
$\\newcommand{\\lzero}[1]{\\norm{#1}_0}$
$\\newcommand{\\lone}[1]{\\norm{#1}_1}$
$\\newcommand{\\ltwo}[1]{\\norm{#1}_2}$
$\\newcommand{\\pnorm}[1]{\\norm{#1}_p}$
'`


<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r}
rm(list = ls())
knitr::opts_chunk$set(
  echo =    T,          # don't show code
  include = T,          # show output
  warning = F,       # don't show warnings
  message = F,       # don't show messages (less serious warnings)
  cache   = T,       # F unless runtime is very long
  # root.dir = 'location_of_dependencies'
  fig.align = "center"
)
```

```{r}
# for lalonde data
library(LalRUtils)

# load library
library(renyiWeights)
```

# Entropy Balancing

The Entropy balancing section builds on Hainmueller(2012) and accompanying r package `ebal`.

Entropy balancing for causal inference involves solving for balancing weights $w_i$ that solves the following (convex) program

\begin{align*}
  \max_{\mathbf{w}} H(w) &= - \sum_{i : i \in \mathcal{S} } w_i \log w_i \\
  \text{Balance constraints:} & \sum_{i : i \in \mathcal{S}} w_i c_{ri}(\mathbf{X}_i) =  m_r(X_j) \text{ with } r \in 1, \dots, R   \\
  \text{Proper weights:} & \sum_{i : i \in \mathcal{S}} w_i = 1 \; \; \text{and } w_i \geq
  0 \; \forall \; \{i: i \in \mathcal{S} \}
\end{align*}

This convex program has $R$ balance constraints that seek to equate functions $c_{ri}(X_i)$ in a source sample $\mathcal{S}$ to a target value $m_r$.

The dual of this problem is unconstrained and can be solved using Newton-Raphson.

## Basics : computing Average Treatment effect on the Treated (ATT)

In the most straightforward example of entropy balancing, we seek to reweight control observations $\{i: D_i = 0\}$ to match sample moments in the treated sample in order to compute $\Exp{Y^1 - Y^0 | D = 1}$ where the second counterfactual mean $\Exp{Y^0|D=1}$ is computed as a reweighted mean of the control group $\sum_{i: D_i = 0} w_i Y_i$.

```{r}
# %%
############################################################
# ATT
############################################################
data(lalonde.psid); setDT(lalonde.psid); df = lalonde.psid
yn = 're78'; wn = 'treat'; Xn = setdiff(colnames(df), c(yn, wn))

# rest of the code is generic
X = df[get(wn) == 0, ..Xn] |> as.matrix()
# treatment covariate means (for ATT)
target = colMeans2(as.matrix(df[get(wn) == 1, ..Xn]))

# solve for balancing weights (solves dual by default)
ω = entrBal(X, target)

# weighted regression (for robust standard errors)
regdf = rbind(
  # treated obs : uniform weights
  data.table(y = df[get(wn) == 1, get(yn)], w = 1, wt = 1 / sum(df[[wn]])),
  # untreated obs : solved weights
  data.table(y = df[get(wn) == 0, get(yn)], w = 0, wt = ω)
)
feols(y ~ w, weights = ~wt, data = regdf, vcov = "HC1")
```

### Compare primal and dual solutions

```{r}
# %% check that primal and dual solutions are identical
ω_primal = eb_solve_primal(c(1, target), cbind(1, X))
ωs = cbind(ω, ω_primal)
# should lie along 45° line
plot(ωs[, 1], ωs[,2]); abline(0, 1)
```

### Dual v Primal speed comparison
```{r}
library(microbenchmark)
microbenchmark(
  primal = {
    eb_solve_primal(c(1, target), cbind(1, X))
  },
  dual = {
    eb_solve_dual(  c(1, target), cbind(1, X))
  },
  times = 100L
)
```

The dual solver is much faster than the primal.

## Other Estimands: ATE

For the ATE, we need to reweight *both* treatment and control groups to equate covariate averages to the overall sample average.

```{r}
# %%
############################################################
# ATE
############################################################

data(lalonde.exp); setDT(lalonde.exp); df = lalonde.exp
yn = 're78'; wn = 'treat'; Xn = setdiff(colnames(df), c(yn, wn))

X0 = df[get(wn) == 0, ..Xn] |> as.matrix()
X1 = df[get(wn) == 1, ..Xn] |> as.matrix()

# overall covariate means (for ATE)
target2 = colMeans2(as.matrix(df[, ..Xn]))

# solve for balancing weights - treatment obs
ω1 = entrBal(X1, target2)
ω0 = entrBal(X0, target2)

regdf = rbind(
  # treated obs : uniform weights of 1
  data.table(y = df[get(wn)== 1, get(yn)], w = 1, wt = ω1),
  data.table(y = df[get(wn)== 0, get(yn)], w = 0, wt = ω0)
)

feols(y ~ w, weights = ~wt, data = regdf, vcov = "HC1")
```
